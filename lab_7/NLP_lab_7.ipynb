{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - lab 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read the classification of Named Entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Read the API of NER in Clarin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Read the documentation of CCL format or more tourough documentation of CCL format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Sort bills according to their size and take top 50 (largest) bills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_BILLS = 'C:/Users/patry/OneDrive/Pulpit/Studia_II_stopien/NLP/lab_1/ustawy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2000_696.txt': 579582,\n",
       " '1996_465.txt': 420981,\n",
       " '2001_627.txt': 413929,\n",
       " '1997_555.txt': 396494,\n",
       " '2002_1689.txt': 352618,\n",
       " '2000_1186.txt': 275546,\n",
       " '1998_1118.txt': 271036,\n",
       " '1997_117.txt': 262973,\n",
       " '2001_1070.txt': 259359,\n",
       " '2001_1368.txt': 258344,\n",
       " '1997_714.txt': 254133,\n",
       " '2001_499.txt': 252007,\n",
       " '2003_1750.txt': 247958,\n",
       " '2001_1545.txt': 245282,\n",
       " '2000_991.txt': 243718,\n",
       " '2001_1229.txt': 239103,\n",
       " '1994_195.txt': 234195,\n",
       " '2000_1268.txt': 234077,\n",
       " '2003_2277.txt': 233681,\n",
       " '1997_926.txt': 233303,\n",
       " '2000_1104.txt': 231146,\n",
       " '1997_553.txt': 226097,\n",
       " '2004_2065.txt': 218719,\n",
       " '2004_1693.txt': 218389,\n",
       " '2004_880.txt': 216529,\n",
       " '2004_177.txt': 212340,\n",
       " '2003_423.txt': 190810,\n",
       " '1997_349.txt': 188718,\n",
       " '2000_1315.txt': 183107,\n",
       " '1999_930.txt': 182337,\n",
       " '1994_591.txt': 182152,\n",
       " '2004_2533.txt': 180335,\n",
       " '1996_110.txt': 179878,\n",
       " '1997_557.txt': 178805,\n",
       " '1999_95.txt': 175787,\n",
       " '2001_1381.txt': 174145,\n",
       " '2000_136.txt': 168282,\n",
       " '1996_460.txt': 163118,\n",
       " '2001_1438.txt': 161341,\n",
       " '1996_561.txt': 154639,\n",
       " '2001_1188.txt': 152985,\n",
       " '2001_628.txt': 150870,\n",
       " '2001_475.txt': 149411,\n",
       " '2003_2256.txt': 148449,\n",
       " '1998_602.txt': 148194,\n",
       " '2001_906.txt': 143601,\n",
       " '2001_92.txt': 142132,\n",
       " '1996_496.txt': 141328,\n",
       " '1997_153.txt': 136489,\n",
       " '2001_1444.txt': 133784}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_bill_size(filename: str) -> int:\n",
    "\n",
    "    f = os.path.join(PATH_TO_BILLS, filename)\n",
    "    if os.path.isfile(f):\n",
    "        size = os.path.getsize(f)\n",
    "    return size\n",
    "\n",
    "filenames = [_ for _ in os.listdir(PATH_TO_BILLS)]\n",
    "sizes = [get_bill_size(filename) for filename in filenames]\n",
    "bills_sizes_list = {filename:size for (filename, size) in zip(filenames, sizes)}\n",
    "bills_sizes_list_sorted = sorted(bills_sizes_list.items(), key = lambda x: -x[1])\n",
    "bills_sizes_list_sorted_top_50 = bills_sizes_list_sorted[:50]\n",
    "bills_sizes_list_sorted_top_50 = {filename:size for filename, size in bills_sizes_list_sorted_top_50}\n",
    "bills_sizes_list_sorted_top_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use the lemmatized and sentence split documents (from ex. 5) to identify the expressions that consist of consecutive words starting with a capital letter (you will have to look at the inflected form of the word to check its capitalization) that do not occupy the first position in a sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Clarin-PL API to lemmatize and tokenize the bills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CLARIN_RESULT = 'C:/Users/patry/OneDrive/Pulpit/Studia_II_stopien/NLP/lab_4/Wynik'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ustawa',\n",
       " 'z',\n",
       " 'dzień',\n",
       " '30',\n",
       " 'czerwiec',\n",
       " '2000',\n",
       " 'r',\n",
       " '.',\n",
       " 'Prawo',\n",
       " 'własność']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as reg\n",
    "\n",
    "def parse_result(filename: str, path_to_results: str = PATH_TO_CLARIN_RESULT) -> list:\n",
    "  \"\"\" Function returns list with tokenized senetences and lemmatized words within the sentences\"\"\"\n",
    "\n",
    "  f = os.path.join(path_to_results, filename)\n",
    "\n",
    "  if os.path.isfile(f):\n",
    "    with open(f, encoding = 'utf-8') as file:\n",
    "      f = file.read()\n",
    "\n",
    "      # pattern = reg.findall(r'\\<base\\>(\\S+)\\<\\/base\\>\\<ctag\\>(\\w+)', f)\n",
    "      pattern = reg.findall(r'\\<tok\\>\\n\\s+.*\\n.*',f)\n",
    "      pattern = \" \".join(pattern)\n",
    "      capitalized = reg.findall(r'\\<orth\\>(\\S+)<\\/orth\\>', f)\n",
    "      lemmas = reg.findall(r'\\<base\\>(\\S+)\\<\\/base\\>\\<ctag\\>(\\w+)', pattern)\n",
    "      \n",
    "\n",
    "  # temp_list = [word + ':' + tag for (word, tag) in pattern if word != ' ']\n",
    "  result = [word for word, _ in lemmas if word != ' ']\n",
    "  for idx, token in enumerate(capitalized):\n",
    "    if token[0].isupper():\n",
    "        result[idx] = result[idx].capitalize()\n",
    "\n",
    "  return result\n",
    "\n",
    "parse_result('1994_195.txt')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find entity names in a single bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kraków', 'Polska', 'Stany Zjednoczone']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_entity_names(lemmatized_bill: list) -> list:\n",
    "\n",
    "    result = []\n",
    "    idx = 0\n",
    "\n",
    "    while idx < len(lemmatized_bill):\n",
    "        idx += 1\n",
    "        if lemmatized_bill[idx-1] != '.' and lemmatized_bill[idx][0].isupper():\n",
    "            temp_ = [_ for _ in lemmatized_bill[idx:]]\n",
    "            pos = 0\n",
    "            candidates = ''\n",
    "            try:\n",
    "                while temp_[pos][0].isupper():\n",
    "                    candidates += f' {temp_[pos]}'\n",
    "                    pos += 1\n",
    "            except IndexError:\n",
    "                pass\n",
    "            result.append(candidates[1:])\n",
    "            idx += pos\n",
    "    return result\n",
    "\n",
    "# We can test lemmatized and tokenized sentence from the exercise\n",
    "find_entity_names(['Wczoraj', 'w', 'Kraków','mieć', 'miejsce', 'spotkanie', 'prezydenci', 'Polska', 'i', 'Stany', 'Zjednoczone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 6**\n",
    "\n",
    "Compute the frequency of each identified expression and print 50 results with the largest number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ustawa',\n",
       " 'Art',\n",
       " 'Dzieje_(apostolskie)',\n",
       " 'Wega',\n",
       " 'Minister',\n",
       " 'Art',\n",
       " 'Dzieje_(apostolskie)',\n",
       " 'Art',\n",
       " 'Minister Sprawa Wewnętrzny',\n",
       " 'Minister']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_names_list = []\n",
    "\n",
    "try:\n",
    "    for filename in bills_sizes_list_sorted_top_50.keys():\n",
    "        lemmatized_tokenized_list = parse_result(filename)\n",
    "        entities = find_entity_names(lemmatized_tokenized_list)\n",
    "        entity_names_list.extend(entities)\n",
    "except IndexError:\n",
    "    pass\n",
    "entity_names_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nr', 850),\n",
       " ('Art', 416),\n",
       " ('Dzieje_(apostolskie)', 200),\n",
       " ('Policja', 158),\n",
       " ('Kodeks', 118),\n",
       " ('Dziennik', 107),\n",
       " ('Państwowy Straż Pożarny', 106),\n",
       " ('Skarb Państwo', 92),\n",
       " ('Rzeczpospolita Polski', 74),\n",
       " ('D', 65),\n",
       " ('Minister', 62),\n",
       " ('Cn', 60),\n",
       " ('Narodowy Fundusz', 53),\n",
       " ('Prawo', 52),\n",
       " ('Wspólnota Europejski', 44),\n",
       " ('Rozdział', 39),\n",
       " ('Rad', 31),\n",
       " ('Minister Praca', 29),\n",
       " ('Polityka Socjalna', 28),\n",
       " ('Sąd Najwyższy', 28),\n",
       " ('Leśnictwo', 24),\n",
       " ('Przepis', 24),\n",
       " ('Minister Sprawiedliwość', 23),\n",
       " ('Starosta', 23),\n",
       " ('Zmiana', 23),\n",
       " ('Warszawa', 22),\n",
       " ('Minister Ochrona Środowisko', 22),\n",
       " ('Zasoby Naturalny', 22),\n",
       " ('Wojewoda', 21),\n",
       " ('Prezes Rad Minister', 20),\n",
       " ('Organ', 20),\n",
       " ('L', 20),\n",
       " ('Państwo', 19),\n",
       " ('Komendant Główny Policja', 19),\n",
       " ('Sprawiedliwość', 19),\n",
       " ('Olej', 19),\n",
       " ('Rad Minister', 18),\n",
       " ('W', 18),\n",
       " ('Główny Inspektor Nadzór Budowlany', 18),\n",
       " ('I', 17),\n",
       " ('Przetwórstwo Artykuł Rolny', 17),\n",
       " ('Minister Sprawa Wewnętrzny', 16),\n",
       " ('Inspekcja', 16),\n",
       " ('Polski', 16),\n",
       " ('Ordynacja', 15),\n",
       " ('Opieka Społeczny', 14),\n",
       " ('Państwowy', 14),\n",
       " ('Inspekcja Ochrona Środowisko', 14),\n",
       " ('Inspekcja Sanitarny', 13),\n",
       " ('Najwyższy', 13)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "frequency_entity_names = Counter(entity_names_list)\n",
    "frequency_entity_names_sorted = sorted(frequency_entity_names.items(), key = lambda x: -x[1])\n",
    "frequency_entity_names_sorted[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 7**\n",
    "\n",
    "Apply the NER algorithm to identify the named entities in the same set of documents (not lemmatized) using the n82 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firslty we will copy top 50 files from the previous tasks and send it to the Clarin, where we can apply NER algorithm using the n82 model by hands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lpmn_client import download_file, upload_file\n",
    "from lpmn_client import Task\n",
    "\n",
    "\n",
    "task = Task(lpmn='any2txt|wcrft2|liner2({\"model\":\"n82\"})')\n",
    "task.email = \"pkrukowski@student.agh.edu.pl\"\n",
    "\n",
    "file_id = upload_file(\"C:/Users/patry/OneDrive/Pulpit/Studia_II_stopien/NLP/lab_7/files.zip\")  # zip file with the top 50 bills\n",
    "output_file_id = task.run(file_id)\n",
    "download_file(output_file_id, \"./out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 8**\n",
    "\n",
    "Plot the frequency (histogram) of the coarse-grained classes (e.g. nam_adj, nam_eve, nam_fac)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this exercise I used this tutorial: https://github.com/CLARIN-PL/NlpRest2-Tutorials/blob/master/part3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    \n",
    "    def __init__(self, orth, base, ctag):\n",
    "        self.orth = orth\n",
    "        self.base = base\n",
    "        self.ctag = ctag\n",
    "        \n",
    "    def get_orth(self):\n",
    "        return self.orth\n",
    "    \n",
    "    def get_base(self):\n",
    "        return self.base\n",
    "    \n",
    "    def get_ctag(self):\n",
    "        return self.ctag\n",
    "        \n",
    "\n",
    "class Annotation:\n",
    "    \n",
    "    def __init__(self, category, tokens):\n",
    "        self.category = category\n",
    "        self.tokens = tokens\n",
    "        self.lemma = self.get_orth()\n",
    "        \n",
    "    def get_category(self):\n",
    "        return self.category\n",
    "    \n",
    "    def get_tokens(self):\n",
    "        return self.tokens\n",
    "    \n",
    "    def get_orth(self):\n",
    "        return \" \".join([token.get_orth() for token in self.tokens])\n",
    "\n",
    "    def get_base(self):\n",
    "        return \" \".join([token.get_base() for token in self.tokens])\n",
    "    \n",
    "    def get_ctag(self):\n",
    "        return \" \".join([token.get_ctag() for token in self.tokens])\n",
    "    \n",
    "    def get_space(self):\n",
    "        return \" \".join([\"True\" for token in self.tokens])\n",
    "    \n",
    "    def get_lemma(self):\n",
    "        return self.lemma\n",
    "    \n",
    "    def set_lemma(self, lemma):\n",
    "        self.lemma = lemma\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"[%s] %s\" % (self.get_category(), self.get_lemma())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def sentence_ner(sentence):\n",
    "    channels = {}\n",
    "    for token in sentence.iter(\"tok\"):\n",
    "        orth = token.find(\"./orth\").text\n",
    "        base = token.find(\"./lex/base\").text\n",
    "        ctag = token.find(\"./lex/ctag\").text\n",
    "        t = Token(orth, base, ctag)\n",
    "        for channel in token.iter(\"ann\"):            \n",
    "            index = int(channel.text)\n",
    "            chan = channel.attrib[\"chan\"]            \n",
    "            if index > 0:                \n",
    "                channels.setdefault(chan, {}) \\\n",
    "                        .setdefault(index, []) \\\n",
    "                        .append(t)\n",
    "                \n",
    "    annotations = []\n",
    "    for (ann_type, group) in channels.items():\n",
    "        for tokens in group.values():            \n",
    "            an = Annotation(ann_type, tokens)\n",
    "            annotations.append(an)\n",
    "    \n",
    "    return annotations\n",
    "                \n",
    "\n",
    "def ccl_ner(ccl):\n",
    "    tree = ET.fromstring(ccl)\n",
    "    annotations = []\n",
    "    for sentence in tree.iter(\"sentence\"):\n",
    "        annotations += sentence_ner(sentence)\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nam_pro_media_periodic] Dz . U .\n",
      "[nam_org_institution] CZĘŚĆ OGÓLNA\n",
      "[nam_loc_gpe_country] Rzeczypospolitej Polskiej\n",
      "[nam_loc_gpe_country] Rzeczpospolita Polska\n",
      "[nam_oth_currency] złotych\n",
      "[nam_oth_currency] złotych\n",
      "[nam_org_institution] Skarbu Państwa\n",
      "[nam_org_institution] Skarbu Państwa\n",
      "[nam_org_institution] Skarbu Państwa\n",
      "[nam_org_institution] Skarbu Państwa\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "PATH_TO_N82_RESULTS = 'C:/Users/patry/OneDrive/Pulpit/Studia_II_stopien/NLP/lab_7/Wynik.zip'\n",
    "\n",
    "zf = zipfile.ZipFile(PATH_TO_N82_RESULTS, 'r')\n",
    "ccl = zf.read(zf.namelist()[0]).decode(\"utf-8-sig\")\n",
    "annotations = ccl_ner(ccl)\n",
    "for annotation in annotations[:10]:\n",
    "    print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_annotations = {}\n",
    "for filename in zf.namelist():\n",
    "    ccl = zf.read(filename)\n",
    "    document_annotations[filename] =  ccl_ner(ccl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "freq_coarse_grained_class_dict = defaultdict(int)\n",
    "\n",
    "for filename in zf.namelist():\n",
    "    ccl = zf.read(filename)\n",
    "    annotations =  ccl_ner(ccl)\n",
    "    for annotation in annotations:\n",
    "        category = annotation.get_category()\n",
    "        category_parsed = category.split('_')\n",
    "        category_parsed = category_parsed[0] + '_' + category_parsed[1]\n",
    "        freq_coarse_grained_class_dict[category_parsed] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 9 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(freq_coarse_grained_class_dict.keys(), freq_coarse_grained_class_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 9**\n",
    "\n",
    "Display 10 most frequent Named Entities for each coarse-grained type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_coarse_grained_class_entity_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for filename in zf.namelist():\n",
    "    ccl = zf.read(filename)\n",
    "    annotations =  ccl_ner(ccl)\n",
    "    for annotation in annotations:\n",
    "        category = annotation.get_category()\n",
    "        category_parsed = category.split('_')\n",
    "        category_parsed = category_parsed[0] + '_' + category_parsed[1]\n",
    "        entity = annotation.get_lemma()\n",
    "        freq_coarse_grained_class_entity_dict[category_parsed][entity] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################################################\n",
      "#CATEGORY # COUNT#           ENTITY\n",
      "###########################################################\n",
      "# nam_pro # 1534 # Dz . U .                               #\n",
      "# nam_pro # 80   # Dz . Urz                               #\n",
      "# nam_pro # 71   # Ordynacja podatkowa                    #\n",
      "# nam_pro # 64   # Kodeksu karnego                        #\n",
      "# nam_pro # 62   # Monitor Polski                         #\n",
      "# nam_pro # 51   # Spraw Wewnętrznych                     #\n",
      "# nam_pro # 35   # Kodeksu postępowania administracyjnego #\n",
      "# nam_pro # 33   # Kodeksu postępowania karnego           #\n",
      "# nam_pro # 32   # Kodeksu postępowania cywilnego         #\n",
      "# nam_pro # 26   # Natura 2000                            #\n",
      "###########################################################\n",
      "# nam_org # 295  # Skarbu Państwa                         #\n",
      "# nam_org # 291  # Unii Europejskiej                      #\n",
      "# nam_org # 261  # Rada Ministrów                         #\n",
      "# nam_org # 239  # Państwowej Straży Pożarnej             #\n",
      "# nam_org # 233  # Minister Sprawiedliwości               #\n",
      "# nam_org # 213  # Prezes Rady Ministrów                  #\n",
      "# nam_org # 162  # Minister Obrony Narodowej              #\n",
      "# nam_org # 152  # Minister Finansów                      #\n",
      "# nam_org # 137  # Urzędu Ochrony Państwa                 #\n",
      "# nam_org # 114  # EFTA                                   #\n",
      "###########################################################\n",
      "# nam_loc # 812  # Rzeczypospolitej Polskiej              #\n",
      "# nam_loc # 52   # Rzeczpospolita Polska                  #\n",
      "# nam_loc # 51   # Polsce                                 #\n",
      "# nam_loc # 39   # Rzeczpospolitą Polską                  #\n",
      "# nam_loc # 32   # Warszawie                              #\n",
      "# nam_loc # 20   # Warszawy                               #\n",
      "# nam_loc # 19   # Nawóz                                  #\n",
      "# nam_loc # 16   # Warszawa                               #\n",
      "# nam_loc # 11   # Konfederacji Szwajcarskiej             #\n",
      "# nam_loc # 10   # Polską                                 #\n",
      "###########################################################\n",
      "# nam_oth # 293  # zł                                     #\n",
      "# nam_oth # 89   # euro                                   #\n",
      "# nam_oth # 41   # złotych                                #\n",
      "# nam_oth # 29   # EURO                                   #\n",
      "# nam_oth # 14   # PESEL                                  #\n",
      "# nam_oth # 12   # BAT                                    #\n",
      "# nam_oth # 10   # PLN                                    #\n",
      "# nam_oth # 8    # Minister Edukacji Narodowej            #\n",
      "# nam_oth # 7    # NIP                                    #\n",
      "# nam_oth # 7    # ECU                                    #\n",
      "###########################################################\n",
      "# nam_adj # 116  # polski                                 #\n",
      "# nam_adj # 30   # polskiej                               #\n",
      "# nam_adj # 16   # polskiego                              #\n",
      "# nam_adj # 16   # Wojewódzki                             #\n",
      "# nam_adj # 10   # polskim                                #\n",
      "# nam_adj # 9    # polska                                 #\n",
      "# nam_adj # 7    # polską                                 #\n",
      "# nam_adj # 7    # polskich                               #\n",
      "# nam_adj # 7    # mazowiecki                             #\n",
      "# nam_adj # 5    # europejskie                            #\n",
      "###########################################################\n",
      "# nam_liv # 51   # Kasa Chorych                           #\n",
      "# nam_liv # 36   # Straży Granicznej                      #\n",
      "# nam_liv # 24   # Sił Zbrojnych                          #\n",
      "# nam_liv # 21   # Kasy Chorych                           #\n",
      "# nam_liv # 18   # Art                                    #\n",
      "# nam_liv # 18   # Pana                                   #\n",
      "# nam_liv # 16   # Gospodarki Żywnościowej                #\n",
      "# nam_liv # 15   # Krajowego Depozytu                     #\n",
      "# nam_liv # 15   # Pan                                    #\n",
      "# nam_liv # 13   # Kas Chorych                            #\n",
      "###########################################################\n",
      "# nam_eve # 5    # EURO                                   #\n",
      "# nam_eve # 2    # Monitorze Sądowym                      #\n",
      "# nam_eve # 2    # Przejściowego Planu Krajowego          #\n",
      "# nam_eve # 1    # Kodeksu morskiego                      #\n",
      "# nam_eve # 1    # Międzynarodowym Funduszem              #\n",
      "# nam_eve # 1    # Nawóz PK                               #\n",
      "# nam_eve # 1    # Inspektora Nadzoru Wewnętrznego        #\n",
      "# nam_eve # 1    # Europejskiej Karcie Społecznej         #\n",
      "# nam_eve # 1    # II wojny światowej                     #\n",
      "# nam_eve # 1    # Maksymalnym Limitem Pozostałości       #\n",
      "###########################################################\n",
      "# nam_fac # 49   # Inspektor Nadzoru Wewnętrznego         #\n",
      "# nam_fac # 16   # Komendant Główny                       #\n",
      "# nam_fac # 11   # Straży Granicznej                      #\n",
      "# nam_fac # 8    # Mangan                                 #\n",
      "# nam_fac # 6    # Obrony Narodowej                       #\n",
      "# nam_fac # 5    # Krajowego Rejestru Karnego             #\n",
      "# nam_fac # 4    # Molibden                               #\n",
      "# nam_fac # 4    # Zasłużonego Dawcy Przeszczepu          #\n",
      "# nam_fac # 4    # Zatoki Gdańskiej                       #\n",
      "# nam_fac # 3    # Mn                                     #\n",
      "###########################################################\n",
      "# nam_num # 13   # 1                                      #\n",
      "# nam_num # 1    # 112                                    #\n",
      "###########################################################\n"
     ]
    }
   ],
   "source": [
    "print('###########################################################')\n",
    "print('#CATEGORY # COUNT#           ENTITY')\n",
    "for category, entities in freq_coarse_grained_class_entity_dict.items():\n",
    "    print('###########################################################')\n",
    "    for entity, count in list(sorted(entities.items(), key=lambda pair: -pair[1]))[:10]:\n",
    "        print(f'# {category} # {str(count).ljust(4)} # {entity.ljust(38)} #')\n",
    "print('###########################################################')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 10**\n",
    "\n",
    "Display 50 most frequent Named Entities including their count and fine-grained type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_fine_grained_class_entity_dict = defaultdict(int)\n",
    "\n",
    "for filename in zf.namelist():\n",
    "    ccl = zf.read(filename)\n",
    "    annotations =  ccl_ner(ccl)\n",
    "    for annotation in annotations:\n",
    "        category = annotation.get_category()\n",
    "        entity = annotation.get_lemma()\n",
    "        freq_fine_grained_class_entity_dict[(entity, category)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Dz . U .', 'nam_pro_media_periodic'), 1534),\n",
       " (('Rzeczypospolitej Polskiej', 'nam_loc_gpe_country'), 812),\n",
       " (('Skarbu Państwa', 'nam_org_institution'), 295),\n",
       " (('zł', 'nam_oth_currency'), 293),\n",
       " (('Unii Europejskiej', 'nam_org_organization'), 290),\n",
       " (('Rada Ministrów', 'nam_org_institution'), 261),\n",
       " (('Minister Sprawiedliwości', 'nam_org_institution'), 233),\n",
       " (('Prezes Rady Ministrów', 'nam_org_institution'), 213),\n",
       " (('Państwowej Straży Pożarnej', 'nam_org_organization'), 205),\n",
       " (('Minister Obrony Narodowej', 'nam_org_institution'), 162)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_fine_grained_class_entity_dict_sorted_top_50 = sorted(freq_fine_grained_class_entity_dict.items(), key=lambda elem: -elem[1])[:50]\n",
    "freq_fine_grained_class_entity_dict_sorted_top_50[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################################################################\n",
      "# COUNT#                 ENTITY                          # CATEGORY\n",
      "# 1534 # Dz . U .                                        # nam_pro_media_periodic #\n",
      "# 812  # Rzeczypospolitej Polskiej                       # nam_loc_gpe_country    #\n",
      "# 295  # Skarbu Państwa                                  # nam_org_institution    #\n",
      "# 293  # zł                                              # nam_oth_currency       #\n",
      "# 290  # Unii Europejskiej                               # nam_org_organization   #\n",
      "# 261  # Rada Ministrów                                  # nam_org_institution    #\n",
      "# 233  # Minister Sprawiedliwości                        # nam_org_institution    #\n",
      "# 213  # Prezes Rady Ministrów                           # nam_org_institution    #\n",
      "# 205  # Państwowej Straży Pożarnej                      # nam_org_organization   #\n",
      "# 162  # Minister Obrony Narodowej                       # nam_org_institution    #\n",
      "# 152  # Minister Finansów                               # nam_org_institution    #\n",
      "# 137  # Urzędu Ochrony Państwa                          # nam_org_institution    #\n",
      "# 116  # polski                                          # nam_adj_country        #\n",
      "# 114  # EFTA                                            # nam_org_organization   #\n",
      "# 110  # Państwowa Komisja Wyborcza                      # nam_org_institution    #\n",
      "# 104  # Urząd Patentowy                                 # nam_org_institution    #\n",
      "# 103  # Europejskiego Porozumienia o Wolnym Handlu      # nam_org_company        #\n",
      "# 98   # Skarb Państwa                                   # nam_org_institution    #\n",
      "# 98   # Państwowej Komisji Wyborczej                    # nam_org_institution    #\n",
      "# 89   # euro                                            # nam_oth_currency       #\n",
      "# 88   # Prezes Urzędu                                   # nam_org_institution    #\n",
      "# 81   # OKRĘG                                           # nam_org_organization   #\n",
      "# 81   # Okręgowej Komisji Wyborczej                     # nam_org_institution    #\n",
      "# 80   # Dz . Urz                                        # nam_pro_media_periodic #\n",
      "# 73   # Sejmu                                           # nam_org_institution    #\n",
      "# 71   # Ordynacja podatkowa                             # nam_pro_title_document #\n",
      "# 71   # Prezesa Urzędu                                  # nam_org_institution    #\n",
      "# 70   # BSWSG                                           # nam_org_organization   #\n",
      "# 64   # Kodeksu karnego                                 # nam_pro_title_document #\n",
      "# 63   # Ministrem Obrony Narodowej                      # nam_org_institution    #\n",
      "# 62   # Monitor Polski                                  # nam_pro_title          #\n",
      "# 59   # Minister Zdrowia i Opieki Społecznej            # nam_org_institution    #\n",
      "# 57   # Wspólnoty Europejskiej                          # nam_org_organization   #\n",
      "# 55   # WE                                              # nam_org_organization   #\n",
      "# 53   # Sąd Najwyższy                                   # nam_org_institution    #\n",
      "# 53   # Komisji Europejskiej                            # nam_org_institution    #\n",
      "# 52   # Rzeczpospolita Polska                           # nam_loc_gpe_country    #\n",
      "# 52   # Ministra Sprawiedliwości                        # nam_org_institution    #\n",
      "# 51   # Dzienniku Urzędowym Rzeczypospolitej Polskiej \" # nam_org_institution    #\n",
      "# 51   # Polsce                                          # nam_loc_gpe_country    #\n",
      "# 51   # Sądu Najwyższego                                # nam_org_institution    #\n",
      "# 51   # Spraw Wewnętrznych                              # nam_pro_title          #\n",
      "# 51   # Kasa Chorych                                    # nam_liv_person         #\n",
      "# 49   # Senatu                                          # nam_org_institution    #\n",
      "# 49   # Inspektor Nadzoru Wewnętrznego                  # nam_fac_goe            #\n",
      "# 48   # Biura Ochrony Rządu                             # nam_org_institution    #\n",
      "# 47   # Prezes Urzędu Regulacji Energetyki              # nam_org_institution    #\n",
      "# 44   # Straży Granicznej                               # nam_org_institution    #\n",
      "# 44   # Państwową Komisję Wyborczą                      # nam_org_institution    #\n",
      "# 43   # Inspekcji Weterynaryjnej                        # nam_org_institution    #\n",
      "###################################################################################\n"
     ]
    }
   ],
   "source": [
    "print('###################################################################################')\n",
    "print('# COUNT#                 ENTITY                          # CATEGORY')\n",
    "for entity, count in freq_fine_grained_class_entity_dict_sorted_top_50:\n",
    "    entity, category = entity\n",
    "    print(f'# {str(count).ljust(4)} # {entity.ljust(48)}# {category.ljust(22)} #')\n",
    "print('###################################################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 11**\n",
    "\n",
    "Display 5 sentences containing at least 2 recognized named entities with different types. Highlight the recognized spans with color. (For demo application Streamlit might be useful for displaying NER results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_with_annotations = defaultdict(lambda: list())\n",
    "\n",
    "for filename in zf.namelist():\n",
    "    ccl = zf.read(filename)\n",
    "    annotations = ccl_ner(ccl)\n",
    "    for annotation in annotations:\n",
    "        category = annotation.get_category()\n",
    "        entity = annotation.get_orth()\n",
    "        if (category, entity) not in dict_with_annotations[filename]:\n",
    "            dict_with_annotations[filename].append((category, entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_with_sentences_from_50_bills = defaultdict(lambda: list())\n",
    "PATH_TO_50_BILLS = 'C:/Users/patry/OneDrive/Pulpit/Studia_II_stopien/NLP/lab_7/files/'\n",
    "\n",
    "for filename in os.listdir(PATH_TO_50_BILLS):\n",
    "    f = os.path.join(PATH_TO_50_BILLS, filename)\n",
    "\n",
    "    if os.path.isfile(f):\n",
    "        with open(f, encoding = 'utf-8') as file:\n",
    "            f = file.read()\n",
    "            dict_with_sentences_from_50_bills[filename] = f.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_with_sentences = defaultdict(lambda: list())\n",
    "for filename in dict_with_sentences_from_50_bills.keys():\n",
    "    for sentence in dict_with_sentences_from_50_bills[filename]:\n",
    "        categories = [elem[0] for elem in dict_with_annotations[filename]]\n",
    "        entities = [elem[1] for elem in dict_with_annotations[filename]]\n",
    "        for category, entity in zip(categories, entities):\n",
    "            if entity in sentence and (sentence, entity, category) not in dict_with_sentences[filename]:\n",
    "                dict_with_sentences[filename].append((sentence, entity, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = defaultdict(lambda: list())\n",
    "\n",
    "for filename in dict_with_sentences.keys():\n",
    "    for (sentence, entity, category) in dict_with_sentences[filename]:\n",
    "        if category not in [elem[1] for elem in sentences[sentence]]:\n",
    "            sentences[sentence].append((entity, category))\n",
    "sentences = dict([elem for elem in sentences.items() if len(elem[1]) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rzeczypospolitej Polskiej', 'nam_loc_gpe_country'),\n",
       " ('Konwencję paryską', 'nam_pro_title_document'),\n",
       " ('polski', 'nam_adj_country')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "sentence = ' Ilekroć w ustawie jest mowa o:\\n   1) osobie - rozumie się przez to osobę fizyczną lub prawną,\\n   2) osobie zagranicznej - rozumie się przez to osobę niemającą obywatelstwa\\n     polskiego i odpowiednio miejsca zamieszkania albo siedziby bądź poważnego\\n     przedsiębiorstwa na obszarze Rzeczypospolitej Polskiej,\\n   3) przedsiębiorcy - rozumie się przez to osobę prowadzącą w celach\\n     zarobkowych działalność wytwórczą, budowlaną, handlową lub usługową, zwaną\\n     dalej \"działalnością gospodarczą\",\\n   4) umowie międzynarodowej - rozumie się przez to umowę międzynarodową,\\n     której stroną jest Rzeczpospolita Polska,\\n   5) Konwencji paryskiej - rozumie się przez to Akt sztokholmski zmieniający\\n     Konwencję paryską o ochronie własności przemysłowej z dnia 20 marca 1883\\n     r'\n",
    "text_1 = colored('Rzeczpospolita Polska', 'red', attrs=['reverse', 'blink'])\n",
    "text_2 = colored('Konwencję paryską', 'red', attrs=['reverse', 'blink'])\n",
    "text_3 = colored('polskiego', 'red', attrs=['reverse', 'blink'])\n",
    "sentences[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilekroć w ustawie jest mowa o:\n",
      "   1) osobie - rozumie się przez to osobę fizyczną lub prawną,\n",
      "   2) osobie zagranicznej - rozumie się przez to osobę niemającą obywatelstwa\n",
      "     \u001b[5m\u001b[7m\u001b[31mpolskiego\u001b[0m i odpowiednio miejsca zamieszkania albo siedziby bądź poważnego\n",
      "     przedsiębiorstwa na obszarze Rzeczypospolitej Polskiej,\n",
      "   3) przedsiębiorcy - rozumie się przez to osobę prowadzącą w celach\n",
      "     zarobkowych działalność wytwórczą, budowlaną, handlową lub usługową, zwaną\n",
      "     dalej \"działalnością gospodarczą\",\n",
      "   4) umowie międzynarodowej - rozumie się przez to umowę międzynarodową,\n",
      "     której stroną jest \u001b[5m\u001b[7m\u001b[31mRzeczpospolita Polska\u001b[0m,\n",
      "   5) Konwencji paryskiej - rozumie się przez to Akt sztokholmski zmieniający\n",
      "     \u001b[5m\u001b[7m\u001b[31mKonwencję paryską\u001b[0m o ochronie własności przemysłowej z dnia 20 marca 1883\n",
      "     r\n"
     ]
    }
   ],
   "source": [
    "print(f'Ilekroć w ustawie jest mowa o:\\n   1) osobie - rozumie się przez to osobę fizyczną lub prawną,\\n   2) osobie zagranicznej - rozumie się przez to osobę niemającą obywatelstwa\\n     {text_3} i odpowiednio miejsca zamieszkania albo siedziby bądź poważnego\\n     przedsiębiorstwa na obszarze Rzeczypospolitej Polskiej,\\n   3) przedsiębiorcy - rozumie się przez to osobę prowadzącą w celach\\n     zarobkowych działalność wytwórczą, budowlaną, handlową lub usługową, zwaną\\n     dalej \"działalnością gospodarczą\",\\n   4) umowie międzynarodowej - rozumie się przez to umowę międzynarodową,\\n     której stroną jest {text_1},\\n   5) Konwencji paryskiej - rozumie się przez to Akt sztokholmski zmieniający\\n     {text_2} o ochronie własności przemysłowej z dnia 20 marca 1883\\n     r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rzeczpospolitą Polską', 'nam_loc_gpe_country'),\n",
       " ('Unią Europejską', 'nam_org_organization'),\n",
       " ('TOP SECRET', 'nam_eve_human')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ' Informacje niejawne wymieniane przez Rzeczpospolitą Polską z Organizacją\\n   Traktatu Północnoatlantyckiego, Unią Europejską, i Unią Zachodnioeuropejską\\n   oraz z innymi organizacjami międzynarodowymi i państwami, oznaczone klauzulą\\n   \"TOP SECRET\" lub równorzędną'\n",
    "text_1 = colored('Rzeczpospolitą Polską', 'red', attrs=['reverse', 'blink'])\n",
    "text_2 = colored('Unią Europejską', 'red', attrs=['reverse', 'blink'])\n",
    "text_3 = colored('TOP SECRET', 'red', attrs=['reverse', 'blink'])\n",
    "sentences[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Informacje niejawne wymieniane przez \u001b[5m\u001b[7m\u001b[31mRzeczpospolitą Polską\u001b[0m z Organizacją\n",
      "   Traktatu Północnoatlantyckiego, \u001b[5m\u001b[7m\u001b[31mUnią Europejską\u001b[0m, i Unią Zachodnioeuropejską\n",
      "   oraz z innymi organizacjami międzynarodowymi i państwami, oznaczone klauzulą\n",
      "   \"\u001b[5m\u001b[7m\u001b[31mTOP SECRET\u001b[0m\" lub równorzędną\n"
     ]
    }
   ],
   "source": [
    "print(f' Informacje niejawne wymieniane przez {text_1} z Organizacją\\n   Traktatu Północnoatlantyckiego, {text_2}, i Unią Zachodnioeuropejską\\n   oraz z innymi organizacjami międzynarodowymi i państwami, oznaczone klauzulą\\n   \"{text_3}\" lub równorzędną')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Urzędzie Patentowym', 'nam_org_institution'),\n",
       " ('Polsce', 'nam_loc_gpe_country')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ' Pierwszeństwo do uzyskania patentu, prawa ochronnego albo prawa z\\n  rejestracji oznacza się, na zasadach określonych w umowach międzynarodowych,\\n  według daty wystawienia wynalazku, wzoru użytkowego albo wzoru przemysłowego\\n  w Polsce lub za granicą, na wystawie międzynarodowej oficjalnej lub\\n  oficjalnie uznanej, jeżeli zgłoszenie w Urzędzie Patentowym tego wynalazku,\\n  wzoru użytkowego albo wzoru przemysłowego dokonane zostanie w okresie 6\\n  miesięcy od tej daty'\n",
    "text_1 = colored('Urzędzie Patentowym', 'red', attrs=['reverse', 'blink'])\n",
    "text_2 = colored('Polsce', 'red', attrs=['reverse', 'blink'])\n",
    "sentences[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pierwszeństwo do uzyskania patentu, prawa ochronnego albo prawa z\n",
      "  rejestracji oznacza się, na zasadach określonych w umowach międzynarodowych,\n",
      "  według daty wystawienia wynalazku, wzoru użytkowego albo wzoru przemysłowego\n",
      "  w \u001b[5m\u001b[7m\u001b[31mPolsce\u001b[0m lub za granicą, na wystawie międzynarodowej oficjalnej lub\n",
      "  oficjalnie uznanej, jeżeli zgłoszenie w \u001b[5m\u001b[7m\u001b[31mUrzędzie Patentowym\u001b[0m tego wynalazku,\n",
      "  wzoru użytkowego albo wzoru przemysłowego dokonane zostanie w okresie 6\n",
      "  miesięcy od tej daty\n"
     ]
    }
   ],
   "source": [
    "print(f' Pierwszeństwo do uzyskania patentu, prawa ochronnego albo prawa z\\n  rejestracji oznacza się, na zasadach określonych w umowach międzynarodowych,\\n  według daty wystawienia wynalazku, wzoru użytkowego albo wzoru przemysłowego\\n  w {text_2} lub za granicą, na wystawie międzynarodowej oficjalnej lub\\n  oficjalnie uznanej, jeżeli zgłoszenie w {text_1} tego wynalazku,\\n  wzoru użytkowego albo wzoru przemysłowego dokonane zostanie w okresie 6\\n  miesięcy od tej daty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourth sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rzeczypospolitej Polskiej', 'nam_loc_gpe_country'),\n",
       " ('Urzędu Patentowego', 'nam_org_institution'),\n",
       " ('Monitor Polski', 'nam_pro_title')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ' 3, wskazanej przez Prezesa Urzędu Patentowego w drodze obwieszczenia w\\n  Dzienniku Urzędowym Rzeczypospolitej Polskiej \"Monitor Polski\"'\n",
    "text_1 = colored('Rzeczypospolitej Polskiej', 'red', attrs=['reverse', 'blink'])\n",
    "text_2 = colored('Urzędu Patentowego', 'red', attrs=['reverse', 'blink'])\n",
    "text_3 = colored('Monitor Polski', 'red', attrs=['reverse', 'blink'])\n",
    "sentences[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3, wskazanej przez Prezesa \u001b[5m\u001b[7m\u001b[31mUrzędu Patentowego\u001b[0m w drodze obwieszczenia w\n",
      "  Dzienniku Urzędowym \u001b[5m\u001b[7m\u001b[31mRzeczypospolitej Polskiej\u001b[0m \"\u001b[5m\u001b[7m\u001b[31mMonitor Polski\u001b[0m\"\n"
     ]
    }
   ],
   "source": [
    "print(f' 3, wskazanej przez Prezesa {text_2} w drodze obwieszczenia w\\n  Dzienniku Urzędowym {text_1} \"{text_3}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fifth sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Straży Parku', 'nam_pro_title'),\n",
       " ('Straży Parku', 'nam_org_institution'),\n",
       " ('Straży Parku', 'nam_org_company')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ' Zastosowanie przez funkcjonariusza Straży Parku środka przymusu\\n  bezpośredniego powinno odpowiadać potrzebom wynikającym z zaistniałej\\n  sytuacji i zmierzać do podporządkowania się osoby poleceniom wydanym przez\\n  funkcjonariusza'\n",
    "text = colored('Straży Parku', 'red', attrs=['reverse', 'blink'])\n",
    "sentences[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Zastosowanie przez funkcjonariusza \u001b[5m\u001b[7m\u001b[31mStraży Parku\u001b[0m środka przymusu\n",
      "  bezpośredniego powinno odpowiadać potrzebom wynikającym z zaistniałej\n",
      "  sytuacji i zmierzać do podporządkowania się osoby poleceniom wydanym przez\n",
      "  funkcjonariusza\n"
     ]
    }
   ],
   "source": [
    "print(f' Zastosowanie przez funkcjonariusza {text} środka przymusu\\n  bezpośredniego powinno odpowiadać potrzebom wynikającym z zaistniałej\\n  sytuacji i zmierzać do podporządkowania się osoby poleceniom wydanym przez\\n  funkcjonariusza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 12**\n",
    "\n",
    "Answer the following questions:\n",
    "* Which of the method (counting expressions with capital letters vs. NER) worked better for the task concerned with identification of the proper names?\n",
    "* What are the drawbacks of the method based on capital letters?\n",
    "* What are the drawbacks of the method based on NER?\n",
    "* Which of the coarse-grained NER groups has the best and which has the worst results? Try to justify this observation.\n",
    "* Do you think NER is sufficient for identifying different occurrences of the same entity (i.e. consider \"USA\" and \"Stany Zjednoczone\" and \"Stany Zjednoczone Ameryki Północnej\")? If not, can you suggest an algorithm or a tool that would be able to group such names together?\n",
    "* Can you think of a real world problem that would benefit the most from application of Named Entity Recognition algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the method (counting expressions with capital letters vs. NER) worked better for the task concerned with identification of the proper names?**\n",
    "\n",
    "The NER algorithm was able to catch more cases than our algorithm with counting expressions with capital letters used in the task. For example, NER founds the names of currencies (\"zł\") and adjectives derived from proper names are started with a lowercase letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the drawbacks of the method based on capital letters?**\n",
    "\n",
    "Such methods are unlikely to catch instances of names in which certain words are started with a lowercase letter, e.g. such an algorithm will be able to catch the name of a political party \"PiS,\" but \"Prawo i Sprawiedliwość\" will no longer be caught by it. \n",
    "\n",
    "Take, for example, the phrase \"Minister Pracy Senat odwiedził\". Such an algorithm will classify \"Minister Pracy Senat\" as one proper name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the drawbacks of the method based on NER?**\n",
    "\n",
    "It seems to me that one of the biggest drawbacks of the NER algorithm is the fact that the algorithm has problems finding the correct proper name when it is designated ambiguously. For example we can take a look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' Zastosowanie przez funkcjonariusza Straży Parku środka przymusu\\n  bezpośredniego powinno odpowiadać potrzebom wynikającym z zaistniałej\\n  sytuacji i zmierzać do podporządkowania się osoby poleceniom wydanym przez\\n  funkcjonariusza',\n",
       " [('Straży Parku', 'nam_pro_title'),\n",
       "  ('Straży Parku', 'nam_org_institution'),\n",
       "  ('Straży Parku', 'nam_org_company')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sentences.items())[-20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it is probably the first class, while the NER algorithm is not able to extract the appropriate information for disambiguation.\n",
    "\n",
    "I think that NER could also has a problem with some proper names written using abbreviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the coarse-grained NER groups has the best and which has the worst results? Try to justify this observation.**\n",
    "\n",
    "* nam_pro - This class refers to the names of products or brands of various kinds. So it seems to me that the results for this class are bad, because, for example, the \"Kodeks postępowania cywilnego\" or \"Spraw Wewnętrznych\" does not have much to do with products in the broad sense.\n",
    "* nam_org - Some of the results make sense, such as \"Unii Europejskiej\" and some do not, such as \"Prezes Rady Ministrów\" or \"Minister Finansów\".\n",
    "* nam_loc - Most of the results seem reasonable, although the NER algorithm sometimes gets it wrong, such gets wrong in the case of \"Konfederacja Szwajcarska\".\n",
    "* nam_oth - According to the KPWr guidelines, this class includes all those proper names that the algorithm has not assigned to the other classes. Looking at the examples in the KPWr documentation, the proper names in this case were classified quite well. Unfortunately, some of the proper names that should have been assigned to this class have not been assigned to it.\n",
    "* nam_adj - Adjectives of the proper names look like properly classified.\n",
    "* nam_liv - In this case, the NER algorithm did not work well, because this class includes proper names refering to living beings. Instead, the class was assigned proper names such as \"Kasy Chorych\" or \"Sił Zbrojnych\".\n",
    "* nam_eve - This class refers to proper names concerning the names of events. In this case, the NER algorithm did not do well either, we can see that proper names such as \"Przejściowy Plan Krajowy\" or \"Inspektor Nadzoru Wewnętrznego\" were assigned to this class.\n",
    "* nam_fac - The results are not satisfactory in my opinion, for example, \"Komendant Główny\" or \"Krajowy Rejestr Karny\" were misclassified.\n",
    "* nam_num - The results were classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you think NER is sufficient for identifying different occurrences of the same entity (i.e. consider \"USA\" and \"Stany Zjednoczone\" and \"Stany Zjednoczone Ameryki Północnej\")? If not, can you suggest an algorithm or a tool that would be able to group such names together?**\n",
    "\n",
    "Observing the results of previous tasks, one could say that NER will not be able to handle with this task. To improve the algorithm, we could use WordNet to catch such cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you think of a real world problem that would benefit the most from application of Named Entity Recognition algorithm?**\n",
    "\n",
    "Some applications:\n",
    "* Document indexing and search engine - NER can be a tool for indexing and cataloging textual document datasets, like online reports, news, and articles. It could extract meaningful entities from them which will then classify these reports into various classes appropriately. These identified entities can be used for indexing the documents which will help the search engines to perform well for recommending relevant documents based on the search keyword.\n",
    "* Chatbots - The purpose of having the implementation of NER in the chatbot is to find the answers to many fact-based questions and these answers are the entities that can be detected using NER. NER in chatbot systems makes the task of finding answers a lot more efficient as it saves time without having to interact with the customer support staff.\n",
    "* Opinion mining - The entity can be referred as products, individuals, services, etc. NER is considered as one of the important components in opinion mining as it is used to extract the relevant attributes of products or entities. From these extracted data, the opinion analysis can be done accordingly over time to determine whether the product sentiment classification rises or falls (positive or negative).\n",
    "\n",
    "The answer to this question was inspired by the blog https://medium.com/thelorry-product-tech-data/a-quick-overview-named-entity-recognition-ner-in-natural-language-processing-b7a892fad24a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48dbcc2c72bf8d2667201c39bb40034bc4b6c5bee724662a428e26ea68ec9c81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
